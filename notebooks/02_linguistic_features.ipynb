{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90359c5c",
   "metadata": {},
   "source": [
    "# Linguistic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc2a639c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install -q nltk\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "nltk.download('maxent_ne_chunker', quiet=True)\n",
    "nltk.download('words', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967b540a",
   "metadata": {},
   "source": [
    "## PoS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "308d27e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"I have a dream that one day on the red hills of Georgia sons of former slaves and the sons of former slave-owners will be able to sit down together at the table of brotherhood. I have a dream that one day even the state of Mississippi, a state sweltering with the heat of injustice, sweltering with the heat of oppression, will be transformed into an oasis of freedom and justice.\n",
    "\n",
    "I have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by the content of their character. I have a dream . . . I have a dream that one day in Alabama, with its vicious racists, with its governor having his lips dripping with the words ofinterposition and nullification, one day right there in Alabama little black boys and black girls will be ableto join hands with little white boys and white girls as sisters and brothers.\n",
    "\n",
    "I have a dream today . . .\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4592e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42a49c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have a dream that one day on the red hills of Georgia sons of former slaves and the sons of former slave-owners will be able to sit down together at the table of brotherhood.',\n",
       " 'I have a dream that one day even the state of Mississippi, a state sweltering with the heat of injustice, sweltering with the heat of oppression, will be transformed into an oasis of freedom and justice.',\n",
       " 'I have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by the content of their character.',\n",
       " 'I have a dream .',\n",
       " '.',\n",
       " '.',\n",
       " 'I have a dream that one day in Alabama, with its vicious racists, with its governor having his lips dripping with the words ofinterposition and nullification, one day right there in Alabama little black boys and black girls will be ableto join hands with little white boys and white girls as sisters and brothers.',\n",
       " 'I have a dream today .',\n",
       " '.',\n",
       " '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = sent_tokenize(corpus)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d99db7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " \"he's\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aace97a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dream', 'NN'), ('one', 'CD'), ('day', 'NN'), ('red', 'JJ'), ('hills', 'NNS'), ('Georgia', 'NNP'), ('sons', 'NNS'), ('former', 'JJ'), ('slaves', 'NNS'), ('sons', 'NNS'), ('former', 'JJ'), ('slave-owners', 'NNS'), ('able', 'JJ'), ('sit', 'NN'), ('together', 'RB'), ('table', 'JJ'), ('brotherhood', 'NN'), ('.', '.')]\n",
      "[('dream', 'NN'), ('one', 'CD'), ('day', 'NN'), ('even', 'RB'), ('state', 'NN'), ('Mississippi', 'NNP'), (',', ','), ('state', 'NN'), ('sweltering', 'NN'), ('heat', 'NN'), ('injustice', 'NN'), (',', ','), ('sweltering', 'VBG'), ('heat', 'NN'), ('oppression', 'NN'), (',', ','), ('transformed', 'VBD'), ('oasis', 'NN'), ('freedom', 'NN'), ('justice', 'NN'), ('.', '.')]\n",
      "[('dream', 'RB'), ('four', 'CD'), ('little', 'JJ'), ('children', 'NNS'), ('one', 'CD'), ('day', 'NN'), ('live', 'JJ'), ('nation', 'NN'), ('judged', 'VBD'), ('color', 'NN'), ('skin', 'NN'), ('content', 'NN'), ('character', 'NN'), ('.', '.')]\n",
      "[('dream', 'NN'), ('.', '.')]\n",
      "[('.', '.')]\n",
      "[('.', '.')]\n",
      "[('dream', 'NN'), ('one', 'CD'), ('day', 'NN'), ('Alabama', 'NNP'), (',', ','), ('vicious', 'JJ'), ('racists', 'NNS'), (',', ','), ('governor', 'NN'), ('lips', 'NNS'), ('dripping', 'VBG'), ('words', 'NNS'), ('ofinterposition', 'NN'), ('nullification', 'NN'), (',', ','), ('one', 'CD'), ('day', 'NN'), ('right', 'JJ'), ('Alabama', 'NNP'), ('little', 'JJ'), ('black', 'JJ'), ('boys', 'NNS'), ('black', 'JJ'), ('girls', 'NNS'), ('ableto', 'VBP'), ('join', 'VB'), ('hands', 'NNS'), ('little', 'JJ'), ('white', 'JJ'), ('boys', 'NNS'), ('white', 'JJ'), ('girls', 'NNS'), ('sisters', 'NNS'), ('brothers', 'NNS'), ('.', '.')]\n",
      "[('dream', 'NN'), ('today', 'NN'), ('.', '.')]\n",
      "[('.', '.')]\n",
      "[('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    tokens = word_tokenize(sentence)\n",
    "    filtered = [word for word in tokens if word.lower() not in stop_words]\n",
    "    pos_tags = nltk.pos_tag(filtered)\n",
    "    print(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bebeacb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Martin', 'Luther', 'King', 'Jr.', 'has', 'a', 'dream']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Martin Luther King Jr. has a dream\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5cff0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Martin', 'NNP'), ('Luther', 'NNP'), ('King', 'NNP'), ('Jr.', 'NNP'), ('has', 'VBZ'), ('a', 'DT'), ('dream', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.pos_tag(\"Martin Luther King Jr. has a dream\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c158ddfe",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4102b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_sentence = \"My name is Miguel O'Hara. I'm this dimension's one and only Spider-Man. At least I was. But I'm not like the others. I don't always like what I have to do, but I know I have to be the one to do it. I've given up too much to stop now.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "857704c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Miguel', 'PERSON')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(ner_sentence)\n",
    "tagged_tokens = nltk.pos_tag(tokens)\n",
    "chunk_tree = nltk.ne_chunk(tagged_tokens)\n",
    "entities = []\n",
    "for subtree in chunk_tree:\n",
    "    if hasattr(subtree, \"label\"):\n",
    "        label = subtree.label()\n",
    "        name = \" \".join(token for token, _ in subtree.leaves())\n",
    "        entities.append((name, label))\n",
    "entities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
